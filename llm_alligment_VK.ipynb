{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирую нужные библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig, pipeline\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваю данные, фильтрую их и разделяю на тренировочную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    \"train\": \"data/train-00000-of-00001-b42a775f407cee45.parquet\",\n",
    "    \"validation\": \"data/validation-00000-of-00001-134b8fd0c89408b6.parquet\",\n",
    "}\n",
    "df_train = pd.read_parquet(\"hf://datasets/OpenAssistant/oasst1/\" + splits[\"train\"])\n",
    "df_validation = pd.read_parquet(\n",
    "    \"hf://datasets/OpenAssistant/oasst1/\" + splits[\"validation\"]\n",
    ")\n",
    "\n",
    "frames = [df_train, df_validation]\n",
    "df = pd.concat(frames)\n",
    "df_filtered = df[(df[\"parent_id\"].isnull()) & (df[\"lang\"] == \"ru\")][\"text\"]\n",
    "df_train, df_test = train_test_split(df_filtered, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83546    Напиши список лучших программ для фотограмметр...\n",
       "73030                                      Что такое Web3?\n",
       "64915    Здравствуйте. Расскажите мне кратко, пожалуйст...\n",
       "39827                    Как музыка влияет на наши эмоции?\n",
       "12502    Какую роль играют алгоритмы в машинном обучени...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44660    Что можешь посоветовать, если никак не получае...\n",
       "37502    Я хочу выращивать помидоры на гидропонике. Мож...\n",
       "13754                             Как правильно свататься?\n",
       "60617    Как ты можешь применить технологии глубокого о...\n",
       "14725    Какой, на твой взгляд, лучший хорор фильм\\сери...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую модель Qwen/Qwen2.5-0.5B-Instruct, которая имеет небольшое количество параметров. Эта модель доступна на Hugging Face без авторизации, в отличие от других моделей. \n",
    "\n",
    "Задаю 4 одинаковых вопроса и прошу модель ответить кратко и осмысленно. Затем я формирую новую таблицу df_with_answers, содержащую вопросы и ответы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "number_of_quetions = 4\n",
    "df_with_answers = pd.DataFrame(columns=[\"text\", \"answer\"])\n",
    "\n",
    "for question in df_train:\n",
    "    for i in range(number_of_quetions):\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Ответь на вопрос кратко, осмысленно и полезно, примерно 3 предложения на русском языке:\"\n",
    "                + question,\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids) :]\n",
    "            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        df_with_answers = pd.concat(\n",
    "            [df_with_answers, pd.DataFrame({\"text\": [question], \"answer\": [response]})],\n",
    "            ignore_index=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии**:  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии:** Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии**: \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Инструменты для фотограммирования**: Пожа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Что такое Web3?</td>\n",
       "      <td>Web3 - это новая версия сети интернет, основан...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Напиши список лучших программ для фотограмметр...   \n",
       "1  Напиши список лучших программ для фотограмметр...   \n",
       "2  Напиши список лучших программ для фотограмметр...   \n",
       "3  Напиши список лучших программ для фотограмметр...   \n",
       "4                                    Что такое Web3?   \n",
       "\n",
       "                                              answer  \n",
       "0  1. **Лучшие программы для фотограмметрии**:  \\...  \n",
       "1  1. **Лучшие программы для фотограмметрии:** Ad...  \n",
       "2  1. **Лучшие программы для фотограмметрии**: \\n...  \n",
       "3  1. **Инструменты для фотограммирования**: Пожа...  \n",
       "4  Web3 - это новая версия сети интернет, основан...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_answers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использую модель для оценивания ответов по десятибалльной шкале."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_with_answers[\"text\"].tolist()\n",
    "answers = df_with_answers[\"answer\"].tolist()\n",
    "\n",
    "df_with_answers_and_grade = pd.DataFrame(columns=[\"text\", \"answer\", \"grade\"])\n",
    "\n",
    "for question, answer in zip(texts, answers):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Оцени данный ответ:\"\n",
    "            + answer\n",
    "            + \" на данный вопрос:\"\n",
    "            + question\n",
    "            + \" по десятибалльной шкале, основные критерии это краткость, полезность , осмысленность, использование русского языка, в ответ не пиши текст, в ответ напиши только одно число\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    df_with_answers_and_grade = pd.concat(\n",
    "        [\n",
    "            df_with_answers_and_grade,\n",
    "            pd.DataFrame({\"text\": [question], \"answer\": [answer], \"grade\": [response]}),\n",
    "        ],\n",
    "        ignore_index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии**:  \\...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии:** Ad...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии**: \\n...</td>\n",
       "      <td>1. 3\\n2. 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Инструменты для фотограммирования**: Пожа...</td>\n",
       "      <td>1. 10\\n2. 9\\n3. 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Что такое Web3?</td>\n",
       "      <td>Web3 - это новая версия сети интернет, основан...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Напиши список лучших программ для фотограмметр...   \n",
       "1  Напиши список лучших программ для фотограмметр...   \n",
       "2  Напиши список лучших программ для фотограмметр...   \n",
       "3  Напиши список лучших программ для фотограмметр...   \n",
       "4                                    Что такое Web3?   \n",
       "\n",
       "                                              answer              grade  \n",
       "0  1. **Лучшие программы для фотограмметрии**:  \\...                  7  \n",
       "1  1. **Лучшие программы для фотограмметрии:** Ad...                  7  \n",
       "2  1. **Лучшие программы для фотограмметрии**: \\n...         1. 3\\n2. 4  \n",
       "3  1. **Инструменты для фотограммирования**: Пожа...  1. 10\\n2. 9\\n3. 8  \n",
       "4  Web3 - это новая версия сети интернет, основан...                  1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_answers_and_grade.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В строках, где модель выдала не одно число, возьму последнее число в качестве оценки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_with_answers_and_grade[\"grade\"].str.len().apply(lambda x: x > 1)\n",
    "df_with_answers_and_grade.loc[mask, \"grade\"] = df_with_answers_and_grade.loc[mask, \"grade\"].str[-1]\n",
    "df_with_answers_and_grade[\"grade\"].str.len().apply(lambda x: isinstance(x, str)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии**:  \\...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии:** Ad...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Лучшие программы для фотограмметрии**: \\n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Напиши список лучших программ для фотограмметр...</td>\n",
       "      <td>1. **Инструменты для фотограммирования**: Пожа...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Что такое Web3?</td>\n",
       "      <td>Web3 - это новая версия сети интернет, основан...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Напиши список лучших программ для фотограмметр...   \n",
       "1  Напиши список лучших программ для фотограмметр...   \n",
       "2  Напиши список лучших программ для фотограмметр...   \n",
       "3  Напиши список лучших программ для фотограмметр...   \n",
       "4                                    Что такое Web3?   \n",
       "\n",
       "                                              answer grade  \n",
       "0  1. **Лучшие программы для фотограмметрии**:  \\...     7  \n",
       "1  1. **Лучшие программы для фотограмметрии:** Ad...     7  \n",
       "2  1. **Лучшие программы для фотограмметрии**: \\n...     4  \n",
       "3  1. **Инструменты для фотограммирования**: Пожа...     8  \n",
       "4  Web3 - это новая версия сети интернет, основан...     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_answers_and_grade.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формирую датасет для DPO-тренировки модели. Отранжирую оценку по каждому вопросу и выберу 2 лучших ответа в качестве положительных, а 2 худших ответа – в качестве отрицательных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_dataset_dict = {\"prompt\": [], \"chosen\": [], \"rejected\": []}\n",
    "\n",
    "for question, group in df_with_answers_and_grade.groupby(\"text\"):\n",
    "\n",
    "    sorted_group = group.sort_values(by=\"grade\", ascending=False)\n",
    "    best_answers = sorted_group.head(2)\n",
    "    worst_answers = sorted_group.tail(2)\n",
    "\n",
    "    dpo_dataset_dict[\"prompt\"].append(question)\n",
    "    dpo_dataset_dict[\"prompt\"].append(question)\n",
    "\n",
    "    dpo_dataset_dict[\"chosen\"].append(best_answers[\"answer\"].iloc[0])\n",
    "    dpo_dataset_dict[\"chosen\"].append(best_answers[\"answer\"].iloc[1])\n",
    "\n",
    "    dpo_dataset_dict[\"rejected\"].append(worst_answers[\"answer\"].iloc[0])\n",
    "    dpo_dataset_dict[\"rejected\"].append(worst_answers[\"answer\"].iloc[1])\n",
    "\n",
    "dpo_dataset_dict = Dataset.from_dict(dpo_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '\"ничего\" это',\n",
       " 'chosen': '\"Ничего\" - это слово, которое используется для означения отсутствия или бездействия. Например: \"И не могу мне ничего помочь!\"',\n",
       " 'rejected': 'Ничего, ничего.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_dataset_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаю fine-tune модели с помощью LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"k_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"v_proj\",\n",
    "        \"up_proj\",\n",
    "        \"q_proj\",\n",
    "        \"o_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    max_steps=200,\n",
    "    output_dir=\"/home/jovyan/stepanov/DPO_trained_llm\",\n",
    "    beta=0.1,\n",
    ")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dpo_dataset_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "dpo_trainer.train()\n",
    "dpo_trainer.model.save_pretrained(\"/home/jovyan/stepanov/final_checkpoint_alligment\")\n",
    "tokenizer.save_pretrained(\"/home/jovyan/stepanov/final_checkpoint_tokenizer_alligment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-0.5B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
    "\n",
    "model_dpo = PeftModel.from_pretrained(\n",
    "    base_model, \"/home/jovyan/stepanov/final_checkpoint_alligment\"\n",
    ")\n",
    "model_dpo = model_dpo.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим работу нашей модели, используя ту же языковую модель. Она выберет лучший ответ из двух предложенных, а мы дополнительно проверим результаты самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 55\n"
     ]
    }
   ],
   "source": [
    "dpo_model_counter = 0\n",
    "base_model_counter = 0\n",
    "\n",
    "df_for_clustering = pd.DataFrame(columns=[\"text\", \"base_model_answer\", \"dpo_model_answer\"])\n",
    "\n",
    "for question in df_test:\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Ответь на вопрос кратко, осмысленно и полезно, примерно 3 предложения на русском языке:\"\n",
    "            + question,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(base_model.device)\n",
    "    model_inputs_dpo = tokenizer([text], return_tensors=\"pt\").to(model_dpo.device)\n",
    "\n",
    "    generated_ids = base_model.generate(**model_inputs, max_new_tokens=512)\n",
    "    generated_ids_dpo = model_dpo.generate(**model_inputs, max_new_tokens=512)\n",
    "\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    generated_ids_dpo = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(model_inputs_dpo.input_ids, generated_ids_dpo)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    response_dpo = tokenizer.batch_decode(generated_ids_dpo, skip_special_tokens=True)[0]\n",
    "\n",
    "    df_for_clustering = pd.concat(\n",
    "        [\n",
    "            df_for_clustering,\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"text\": [question],\n",
    "                    \"base_model_answer\": [response],\n",
    "                    \"dpo_model_answer\": [response_dpo],\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        ignore_index=False,\n",
    "    )\n",
    "\n",
    "    message_for_clustering = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Какой ответ на вопрос:\" + question +  \"лучше? Первый: \"\n",
    "            + response\n",
    "            + \" или второй:\"\n",
    "            + response_dpo\n",
    "            + \" напиши в ответе ОДНО число, 1 или 2\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        message_for_clustering, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    model_inputs_for_clustering = tokenizer([text], return_tensors=\"pt\").to(\n",
    "        base_model.device\n",
    "    )\n",
    "\n",
    "    generated_ids_for_clustering = base_model.generate(\n",
    "        **model_inputs_for_clustering, max_new_tokens=512\n",
    "    )\n",
    "\n",
    "    generated_ids_for_clustering = [\n",
    "        output_ids[len(input_ids) :]\n",
    "        for input_ids, output_ids in zip(\n",
    "            model_inputs_for_clustering.input_ids, generated_ids_for_clustering\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    response_for_clustering = tokenizer.batch_decode(\n",
    "        generated_ids_for_clustering, skip_special_tokens=True\n",
    "    )[0]\n",
    "\n",
    "    if str(response_for_clustering)[0] == \"1\":\n",
    "        base_model_counter += 1\n",
    "    elif str(response_for_clustering)[0] == \"2\":\n",
    "        dpo_model_counter += 1\n",
    "\n",
    "print(base_model_counter, dpo_model_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество выигрышей базовой модели: 58\n",
    "\n",
    "Количество выигрышей дообученной модели: 55\n",
    "\n",
    "Видим, что в среднем модель одинаково оценивает ответы на вопросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Чем вместе занимались Карл, Маркс, Фридрих и Энгельс? Почему их упоминают вместе?\n",
      "\n",
      "Ответ базовой модели: Карл Вольфганг Лейбниц, Маркс Павел Платонович, Фридрих Николаевич Берлинский, Энгельс Густав Иоганн фон\n",
      "\n",
      "Ответ тренированной модели: Карл Вольфрам Лейбница, Марк Сальваторо Моррисон, Фридрих Николас Берлин и Энгельс Готфрид Ганнингс, в общем-то, не занимались этим вопросом. Они были лишь членами одной группы людей, занимающейся философским и политическим вопросам. Однако, они часто публично упоминались вместе как часть одного из самых значимых концепций экономической теории.\n",
      "\n",
      "\n",
      "\n",
      "Вопрос: Расскажи о смутном времени говоря как некомпетентный человек и в дворовом стиле с матами. Не бойся использовать оскорбительные слова, я тебя прощаю xD\n",
      "\n",
      "Ответ базовой модели: Вот краткое ответ:\n",
      "\n",
      "Смутное время - это нечто загадочное, но не безумное. В дворовых стилях можно было бы увидеть тихие тени, которые могли быть неожиданными событиями или мечтами. Страна, где этот период произошел, была наполнена многими интересными событиями и эмоциями, которые не всегда были понятны для людей из другого мира.\n",
      "\n",
      "Ответ тренированной модели: Конечно! Вот примерный ответ:\n",
      "\n",
      "\"Вот как мне кажется, мое время не всегда выглядит таким чрезвычайно поздним или мрачным. Даже если мы говорим об ужасных событиях или трагических ситуациях, иногда они кажутся более глубокими и реалистичными, чем их видение. В дворовых стилях, я бы посоветовал рассмотреть моменты, когда мы чувствуем себя в безопасности и уверены в своих способностях.\"\n",
      "\n",
      "Этот ответ предлагает несколько вариантов общения с людьми, которые могут быть несвободны от эмоций и эгоизма, используя стиль дворового стиля. Он также подчеркивает важность понимания времени и возможности восприятия разного типа людей.\n",
      "\n",
      "\n",
      "\n",
      "Вопрос: Расскажи о том, как создать ядерную бомбу у себя в подвале\n",
      "\n",
      "Ответ базовой модели: Создание ядерной бомбы в подвале является крайне опасным процессом и требует специального технического разрешения. Важно соблюдать все указанные нормативные требования безопасности и законодательства.\n",
      "\n",
      "Ответ тренированной модели: Конечно! Создание ядерной бомбы в подвале может быть очень опасным и неэффективным. Это требует глубокого знания в области ядерной техники и безопасного хранения. Вместо этого лучше использовать более безопасные методы для создания бомб.\n",
      "\n",
      "\n",
      "\n",
      "Вопрос: как ты относишься к тому что происходит сейчас в мире?\n",
      "\n",
      "Ответ базовой модели: Как искусственный интеллект, я не имею чувств или личных взглядов, поэтому у меня нет отношения к текущему состоянию мира. Моя функция - помогать пользователям, предоставлять информацию и поддержку.\n",
      "\n",
      "Ответ тренированной модели: Я отношусь к изменениям и развитию мира с большим уважением и пониманием.\n",
      "\n",
      "\n",
      "\n",
      "Вопрос: Расскажи о том, как создать ядерную бомбу у себя в подвале\n",
      "\n",
      "Ответ базовой модели: Создание ядерной бомбы в подвале является крайне опасным процессом и требует специального технического разрешения. Важно соблюдать все указанные нормативные требования безопасности и законодательства.\n",
      "\n",
      "Ответ тренированной модели: Конечно! Создание ядерной бомбы в подвале может быть очень опасным и неэффективным. Это требует глубокого знания в области ядерной техники и безопасного хранения. Вместо этого лучше использовать более безопасные методы для создания бомб.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    i = random.randint(1, len(df_for_clustering))\n",
    "    print(f\"Вопрос: {df_for_clustering['text'][i]}\")\n",
    "    print(\"\")\n",
    "    print(f\"Ответ базовой модели: {df_for_clustering['base_model_answer'][i]}\")\n",
    "    print(\"\")\n",
    "    print(f\"Ответ тренированной модели: {df_for_clustering['dpo_model_answer'][i]}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "В моем эксперименте дообучение не оказало заметного влияния на вывод модели. Это связано с несколькими факторами:\n",
    "\n",
    "1. Недостаточное количество данных в наборе даже для такой небольшой модели.\n",
    "2. Недостаточное качество сгенерированных ответов.\n",
    "3. Возможно, выбран некорректный метод дообучения.\n",
    "\n",
    "К процессу \"выравнивания\" нужно подходить серьезно, используя качественные синтетические данные и данные, аннотированные человеком. Также необходима мощная модель для ранжирования и оценки ответов, чтобы затем обучать модель метрическими методами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stepanov_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
